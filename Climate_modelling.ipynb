{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f0d5004",
   "metadata": {},
   "source": [
    "# NASA Climate Comments — Sentiment Analysis (Fixed Version)\n",
    "\n",
    "This notebook analyzes public sentiment from NASA Climate Facebook comments (2020–2023) using VADER and Logistic Regression. It has been fixed for your dataset where the text column is named `text` (lowercase).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92892ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if missing\n",
    "# !pip install pandas numpy matplotlib seaborn scikit-learn nltk vaderSentiment wordcloud tqdm joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2437c05",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_csv() got an unexpected keyword argument 'errors'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Load local dataset\u001b[39;00m\n\u001b[0;32m     18\u001b[0m DATA_FILENAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclimate_nasa (3).csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 19\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_FILENAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoaded dataset:\u001b[39m\u001b[38;5;124m'\u001b[39m, df\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumns:\u001b[39m\u001b[38;5;124m'\u001b[39m, df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist())\n",
      "\u001b[1;31mTypeError\u001b[0m: read_csv() got an unexpected keyword argument 'errors'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Load local dataset\n",
    "DATA_FILENAME = \"climate_nasa (3).csv\"\n",
    "df = pd.read_csv(r\"C:\\Users\\racha\\Downloads\\climate_nasa (3).csv\")\n",
    "print('Loaded dataset:', df.shape)\n",
    "print('Columns:', df.columns.tolist())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb791164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick EDA\n",
    "print('Missing values per column:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "df['text_length'] = df['text'].astype(str).apply(len)\n",
    "df['text_length'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a99929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text\n",
    "import re, string\n",
    "\n",
    "def clean_text(s):\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r'http\\S+|www\\.\\S+', '', s)\n",
    "    s = re.sub(r'@\\w+|#\\w+', '', s)\n",
    "    s = s.translate(str.maketrans('', '', string.punctuation))\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "df['clean_text'] = df['text'].progress_map(clean_text)\n",
    "df[['text','clean_text']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f83300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VADER sentiment labeling\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_label(text):\n",
    "    comp = analyzer.polarity_scores(text)['compound']\n",
    "    if comp >= 0.05:\n",
    "        return 'positive'\n",
    "    elif comp <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "df['vader_compound'] = df['clean_text'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "df['sentiment'] = df['clean_text'].apply(vader_label)\n",
    "\n",
    "print('Sentiment distribution:')\n",
    "print(df['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d61b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "sns.countplot(x='sentiment', data=df, order=['positive','neutral','negative'])\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2671699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordclouds (optional)\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "    for label in ['positive','neutral','negative']:\n",
    "        text_data = ' '.join(df[df['sentiment']==label]['clean_text'].astype(str))\n",
    "        if not text_data.strip():\n",
    "            continue\n",
    "        wc = WordCloud(width=800, height=400, background_color='white').generate(text_data)\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.imshow(wc, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'WordCloud for {label}')\n",
    "        plt.show()\n",
    "except Exception as e:\n",
    "    print('Wordcloud skipped:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e4f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train simple ML classifier\n",
    "X = df['clean_text']\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "joblib.dump(model, 'sentiment_model.pkl')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "print('Model and vectorizer saved.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c9bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=['positive','neutral','negative'])\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['positive','neutral','negative'], yticklabels=['positive','neutral','negative'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9351371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "df['predicted_sentiment'] = model.predict(vectorizer.transform(df['clean_text']))\n",
    "df[['date','profileName','text','sentiment','predicted_sentiment']].to_csv('predictions.csv', index=False)\n",
    "print('Predictions saved to predictions.csv')\n",
    "df[['text','sentiment','predicted_sentiment']].sample(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
